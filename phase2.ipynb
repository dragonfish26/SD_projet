{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Phase 2: Model Training & Evaluation\n",
    "## Feature Selection, Model Complexity, and Data Comparison\n",
    "\n",
    "**Goal:** Compare the role of different classifiers and feature importance for facial expression recognition\n",
    "\n",
    "**Models Explored:**\n",
    "1. Logistic Regression (with StandardScaler and class_weight='balanced')\n",
    "2. Random Forest Classifier\n",
    "3. Decision Tree Classifier\n",
    "\n",
    "**Analysis Goals:**\n",
    "1. Study the importance of feature subsets (e.g., facial points related to the mouth, eyes, etc.) using Random Forest\n",
    "2. Demonstrate learning curves as a function of model complexity\n",
    "3. Compare models trained on 'geometric' data with 'motion' data\n",
    "4. Measure training and prediction time for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Load both motion and geometric datasets for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load motion data\n",
    "data_motion = pd.read_csv('data_motion.csv')\n",
    "print(\"Motion dataset shape:\", data_motion.shape)\n",
    "\n",
    "# Load geometric data\n",
    "data_geometric = pd.read_csv('data_geometric.csv')\n",
    "print(\"Geometric dataset shape:\", data_geometric.shape)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nMotion data preview:\")\n",
    "print(data_motion.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data",
   "metadata": {},
   "source": [
    "## 2. Prepare Data\n",
    "\n",
    "Split features and labels, then create train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare motion data\n",
    "feature_cols = [col for col in data_motion.columns if col.startswith('x') or col.startswith('y')]\n",
    "X_motion = data_motion[feature_cols]\n",
    "y_motion = data_motion['Emotion']\n",
    "\n",
    "# Prepare geometric data\n",
    "X_geometric = data_geometric[feature_cols]\n",
    "y_geometric = data_geometric['Emotion']\n",
    "\n",
    "# Split motion data\n",
    "X_train_motion, X_test_motion, y_train_motion, y_test_motion = train_test_split(\n",
    "    X_motion, y_motion, test_size=0.2, random_state=42, stratify=y_motion\n",
    ")\n",
    "\n",
    "# Split geometric data\n",
    "X_train_geometric, X_test_geometric, y_train_geometric, y_test_geometric = train_test_split(\n",
    "    X_geometric, y_geometric, test_size=0.2, random_state=42, stratify=y_geometric\n",
    ")\n",
    "\n",
    "print(f\"Motion training set: {X_train_motion.shape}\")\n",
    "print(f\"Motion test set: {X_test_motion.shape}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train_motion.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_logreg",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression\n",
    "\n",
    "Train Logistic Regression with StandardScaler (important for small decimal values) and class_weight='balanced' to address class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logreg_motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the motion data (important for Logistic Regression)\n",
    "scaler_motion = StandardScaler()\n",
    "X_train_motion_scaled = scaler_motion.fit_transform(X_train_motion)\n",
    "X_test_motion_scaled = scaler_motion.transform(X_test_motion)\n",
    "\n",
    "# Train Logistic Regression on motion data\n",
    "print(\"Training Logistic Regression on motion data...\")\n",
    "start_time = time()\n",
    "lr_motion = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "lr_motion.fit(X_train_motion_scaled, y_train_motion)\n",
    "train_time_lr_motion = time() - start_time\n",
    "\n",
    "# Make predictions and measure time\n",
    "start_time = time()\n",
    "y_pred_lr_motion = lr_motion.predict(X_test_motion_scaled)\n",
    "predict_time_lr_motion = (time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_lr_motion = accuracy_score(y_test_motion, y_pred_lr_motion)\n",
    "\n",
    "print(f\"\\nLogistic Regression (Motion Data):\")\n",
    "print(f\"  Training time: {train_time_lr_motion:.2f} seconds\")\n",
    "print(f\"  Prediction time: {predict_time_lr_motion:.2f} milliseconds\")\n",
    "print(f\"  Accuracy: {accuracy_lr_motion:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_motion, y_pred_lr_motion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_rf",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier\n",
    "\n",
    "Train Random Forest and analyze feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf_motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest on motion data\n",
    "print(\"Training Random Forest on motion data...\")\n",
    "start_time = time()\n",
    "rf_motion = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_motion.fit(X_train_motion, y_train_motion)\n",
    "train_time_rf_motion = time() - start_time\n",
    "\n",
    "# Make predictions and measure time\n",
    "start_time = time()\n",
    "y_pred_rf_motion = rf_motion.predict(X_test_motion)\n",
    "predict_time_rf_motion = (time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf_motion = accuracy_score(y_test_motion, y_pred_rf_motion)\n",
    "\n",
    "print(f\"\\nRandom Forest (Motion Data):\")\n",
    "print(f\"  Training time: {train_time_rf_motion:.2f} seconds\")\n",
    "print(f\"  Prediction time: {predict_time_rf_motion:.2f} milliseconds\")\n",
    "print(f\"  Accuracy: {accuracy_rf_motion:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_motion, y_pred_rf_motion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_dt",
   "metadata": {},
   "source": [
    "## 5. Decision Tree Classifier\n",
    "\n",
    "Train Decision Tree for comparison with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dt_motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree on motion data\n",
    "print(\"Training Decision Tree on motion data...\")\n",
    "start_time = time()\n",
    "dt_motion = DecisionTreeClassifier(random_state=42)\n",
    "dt_motion.fit(X_train_motion, y_train_motion)\n",
    "train_time_dt_motion = time() - start_time\n",
    "\n",
    "# Make predictions and measure time\n",
    "start_time = time()\n",
    "y_pred_dt_motion = dt_motion.predict(X_test_motion)\n",
    "predict_time_dt_motion = (time() - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_dt_motion = accuracy_score(y_test_motion, y_pred_dt_motion)\n",
    "\n",
    "print(f\"\\nDecision Tree (Motion Data):\")\n",
    "print(f\"  Training time: {train_time_dt_motion:.2f} seconds\")\n",
    "print(f\"  Prediction time: {predict_time_dt_motion:.2f} milliseconds\")\n",
    "print(f\"  Accuracy: {accuracy_dt_motion:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_motion, y_pred_dt_motion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_feature_importance",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis\n",
    "\n",
    "Use Random Forest feature importance to identify critical facial points.\n",
    "\n",
    "Facial landmark points:\n",
    "- Points 37-48: Eye region (12 points total for both eyes)\n",
    "- Points 49-68: Mouth region (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from Random Forest\n",
    "feature_importance = rf_motion.feature_importances_\n",
    "\n",
    "# Create a dataframe with feature names and importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': feature_importance\n",
    "})\n",
    "\n",
    "# Calculate importance by facial region\n",
    "# Extract point numbers from feature names (e.g., 'x37' -> 37)\n",
    "importance_df['point'] = importance_df['feature'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# Group by regions\n",
    "eye_points = importance_df[importance_df['point'].between(37, 48)]\n",
    "mouth_points = importance_df[importance_df['point'].between(49, 68)]\n",
    "other_points = importance_df[~importance_df['point'].between(37, 68)]\n",
    "\n",
    "# Calculate total importance per region\n",
    "eye_importance = eye_points['importance'].sum()\n",
    "mouth_importance = mouth_points['importance'].sum()\n",
    "other_importance = other_points['importance'].sum()\n",
    "\n",
    "print(\"Feature Importance by Facial Region:\")\n",
    "print(f\"  Eye region (points 37-48): {eye_importance:.4f}\")\n",
    "print(f\"  Mouth region (points 49-68): {mouth_importance:.4f}\")\n",
    "print(f\"  Other regions: {other_importance:.4f}\")\n",
    "\n",
    "# Plot top 20 most important features\n",
    "top_features = importance_df.nlargest(20, 'importance')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 20 Most Important Features (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar chart of regional importance\n",
    "plt.figure(figsize=(8, 5))\n",
    "regions = ['Eyes (37-48)', 'Mouth (49-68)', 'Other']\n",
    "importances = [eye_importance, mouth_importance, other_importance]\n",
    "plt.bar(regions, importances)\n",
    "plt.ylabel('Total Importance')\n",
    "plt.title('Feature Importance by Facial Region')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_learning_curves",
   "metadata": {},
   "source": [
    "## 7. Learning Curves: Model Complexity Study\n",
    "\n",
    "Study how Random Forest accuracy changes with different values of n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning_curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study impact of n_estimators on Random Forest accuracy\n",
    "n_estimators_values = [10, 25, 50, 75, 100, 150, 200]\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "print(\"Evaluating Random Forest with different n_estimators...\")\n",
    "for n_est in n_estimators_values:\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train_motion, y_train_motion)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train_motion, rf.predict(X_train_motion))\n",
    "    test_acc = accuracy_score(y_test_motion, rf.predict(X_test_motion))\n",
    "    \n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(f\"  n_estimators={n_est}: Train={train_acc:.4f}, Test={test_acc:.4f}\")\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_values, train_accuracies, marker='o', label='Training Accuracy')\n",
    "plt.plot(n_estimators_values, test_accuracies, marker='s', label='Test Accuracy')\n",
    "plt.xlabel('Number of Estimators (n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Random Forest: Accuracy vs Model Complexity')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_geometric",
   "metadata": {},
   "source": [
    "## 8. Training Models on Geometric Data\n",
    "\n",
    "Train all three models on geometric data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "models_geometric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale geometric data for Logistic Regression\n",
    "scaler_geometric = StandardScaler()\n",
    "X_train_geometric_scaled = scaler_geometric.fit_transform(X_train_geometric)\n",
    "X_test_geometric_scaled = scaler_geometric.transform(X_test_geometric)\n",
    "\n",
    "# Logistic Regression on geometric data\n",
    "print(\"Training Logistic Regression on geometric data...\")\n",
    "start_time = time()\n",
    "lr_geometric = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "lr_geometric.fit(X_train_geometric_scaled, y_train_geometric)\n",
    "train_time_lr_geo = time() - start_time\n",
    "\n",
    "start_time = time()\n",
    "y_pred_lr_geo = lr_geometric.predict(X_test_geometric_scaled)\n",
    "predict_time_lr_geo = (time() - start_time) * 1000\n",
    "accuracy_lr_geo = accuracy_score(y_test_geometric, y_pred_lr_geo)\n",
    "\n",
    "print(f\"  Training time: {train_time_lr_geo:.2f} seconds\")\n",
    "print(f\"  Prediction time: {predict_time_lr_geo:.2f} milliseconds\")\n",
    "print(f\"  Accuracy: {accuracy_lr_geo:.4f}\")\n",
    "\n",
    "# Random Forest on geometric data\n",
    "print(\"\\nTraining Random Forest on geometric data...\")\n",
    "start_time = time()\n",
    "rf_geometric = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_geometric.fit(X_train_geometric, y_train_geometric)\n",
    "train_time_rf_geo = time() - start_time\n",
    "\n",
    "start_time = time()\n",
    "y_pred_rf_geo = rf_geometric.predict(X_test_geometric)\n",
    "predict_time_rf_geo = (time() - start_time) * 1000\n",
    "accuracy_rf_geo = accuracy_score(y_test_geometric, y_pred_rf_geo)\n",
    "\n",
    "print(f\"  Training time: {train_time_rf_geo:.2f} seconds\")\n",
    "print(f\"  Prediction time: {predict_time_rf_geo:.2f} milliseconds\")\n",
    "print(f\"  Accuracy: {accuracy_rf_geo:.4f}\")\n",
    "\n",
    "# Decision Tree on geometric data\n",
    "print(\"\\nTraining Decision Tree on geometric data...\")\n",
    "start_time = time()\n",
    "dt_geometric = DecisionTreeClassifier(random_state=42)\n",
    "dt_geometric.fit(X_train_geometric, y_train_geometric)\n",
    "train_time_dt_geo = time() - start_time\n",
    "\n",
    "start_time = time()\n",
    "y_pred_dt_geo = dt_geometric.predict(X_test_geometric)\n",
    "predict_time_dt_geo = (time() - start_time) * 1000\n",
    "accuracy_dt_geo = accuracy_score(y_test_geometric, y_pred_dt_geo)\n",
    "\n",
    "print(f\"  Training time: {train_time_dt_geo:.2f} seconds\")\n",
    "print(f\"  Prediction time: {predict_time_dt_geo:.2f} milliseconds\")\n",
    "print(f\"  Accuracy: {accuracy_dt_geo:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_comparison",
   "metadata": {},
   "source": [
    "## 9. Comparison Table: Motion vs Geometric Data\n",
    "\n",
    "Compare the performance of all models on both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Decision Tree'] * 2,\n",
    "    'Dataset': ['Motion'] * 3 + ['Geometric'] * 3,\n",
    "    'Accuracy': [\n",
    "        accuracy_lr_motion, accuracy_rf_motion, accuracy_dt_motion,\n",
    "        accuracy_lr_geo, accuracy_rf_geo, accuracy_dt_geo\n",
    "    ],\n",
    "    'Train Time (s)': [\n",
    "        train_time_lr_motion, train_time_rf_motion, train_time_dt_motion,\n",
    "        train_time_lr_geo, train_time_rf_geo, train_time_dt_geo\n",
    "    ],\n",
    "    'Predict Time (ms)': [\n",
    "        predict_time_lr_motion, predict_time_rf_motion, predict_time_dt_motion,\n",
    "        predict_time_lr_geo, predict_time_rf_geo, predict_time_dt_geo\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nComparison Table: Motion vs Geometric Data\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualization of accuracy comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "motion_accuracies = [accuracy_lr_motion, accuracy_rf_motion, accuracy_dt_motion]\n",
    "geometric_accuracies = [accuracy_lr_geo, accuracy_rf_geo, accuracy_dt_geo]\n",
    "models = ['Logistic\\nRegression', 'Random\\nForest', 'Decision\\nTree']\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, motion_accuracies, width, label='Motion Data')\n",
    "plt.bar(x + width/2, geometric_accuracies, width, label='Geometric Data')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance: Motion vs Geometric Data')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_analysis",
   "metadata": {},
   "source": [
    "## 10. Analysis and Interpretation\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Motion vs Geometric Data**: \n",
    "   - Motion data represents the change in facial landmarks over time (delta values)\n",
    "   - Geometric data represents the actual positions of facial landmarks\n",
    "   - Performance differences can be attributed to how each representation captures facial expressions\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - The mouth region (points 49-68) and eye region (points 37-48) show different importance levels\n",
    "   - This helps identify which facial areas are most critical for emotion classification\n",
    "\n",
    "3. **Model Complexity**:\n",
    "   - The learning curve shows how increasing n_estimators affects Random Forest performance\n",
    "   - Helps identify the optimal trade-off between accuracy and computational cost\n",
    "\n",
    "4. **Model Comparison**:\n",
    "   - Logistic Regression benefits from StandardScaler and class_weight='balanced'\n",
    "   - Random Forest typically performs well without scaling\n",
    "   - Decision Tree is fast but may overfit without pruning\n",
    "\n",
    "5. **Time Performance**:\n",
    "   - Training time varies significantly between models\n",
    "   - Prediction time is important for real-time applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}