{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Phase 2: Model Training & Evaluation\n",
    "## Feature Selection, Model Complexity, and Data Comparison\n",
    "\n",
    "**Goal:** Compare the role of different classifiers and feature importance for facial expression recognition\n",
    "\n",
    "**Models Explored:**\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. Decision Tree\n",
    "\n",
    "**Analysis Goals:**\n",
    "1. Study the importance of feature subsets (e.g., facial points related to the mouth, eyes, etc.) using Random Forest\n",
    "2. Demonstrate learning curves as a function of model complexity\n",
    "3. Compare models trained on 'geometric' data with 'motion' data\n",
    "4. Measure model training and inference timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "### Load both 'motion' and 'geometric' datasets\n",
    "\n",
    "The motion dataset contains temporal differences in facial landmark positions between consecutive frames.\n",
    "The geometric dataset contains normalized spatial positions of facial landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_motion = pd.read_csv('data_motion.csv')\n",
    "data_geometric = pd.read_csv('data_geometric.csv')\n",
    "\n",
    "print(\"Motion dataset shape:\", data_motion.shape)\n",
    "print(\"Geometric dataset shape:\", data_geometric.shape)\n",
    "print(\"\\nLabel distribution in motion dataset:\")\n",
    "print(data_motion['Emotion'].value_counts().sort_index())\n",
    "\n",
    "# Prepare data - separate features and labels\n",
    "# Remove non-feature columns: Subject, Subject_Clean, Session_Clean, Emotion\n",
    "feature_cols = [col for col in data_motion.columns if col not in ['Subject', 'Subject_Clean', 'Session_Clean', 'Emotion']]\n",
    "\n",
    "X_motion = data_motion[feature_cols]\n",
    "y_motion = data_motion['Emotion']\n",
    "\n",
    "X_geometric = data_geometric[feature_cols]\n",
    "y_geometric = data_geometric['Emotion']\n",
    "\n",
    "print(\"\\nNumber of features:\", len(feature_cols))\n",
    "print(\"Feature columns (first 10):\", feature_cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split motion data into train and test sets\n",
    "X_train_motion, X_test_motion, y_train_motion, y_test_motion = train_test_split(\n",
    "    X_motion, y_motion, test_size=0.2, random_state=42, stratify=y_motion\n",
    ")\n",
    "\n",
    "# Split geometric data into train and test sets\n",
    "X_train_geometric, X_test_geometric, y_train_geometric, y_test_geometric = train_test_split(\n",
    "    X_geometric, y_geometric, test_size=0.2, random_state=42, stratify=y_geometric\n",
    ")\n",
    "\n",
    "print(\"Motion - Training set size:\", X_train_motion.shape[0])\n",
    "print(\"Motion - Test set size:\", X_test_motion.shape[0])\n",
    "print(\"\\nGeometric - Training set size:\", X_train_geometric.shape[0])\n",
    "print(\"Geometric - Test set size:\", X_test_geometric.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression\n",
    "\n",
    "### Comparison with and without StandardScaler\n",
    "\n",
    "Logistic Regression can benefit from feature standardization, especially when features have different scales.\n",
    "We will compare performance with and without StandardScaler to evaluate its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logreg_without_scaler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression WITHOUT StandardScaler\n",
    "print(\"=== Logistic Regression WITHOUT StandardScaler ===\")\n",
    "\n",
    "start_time = time()\n",
    "lr_no_scale = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_no_scale.fit(X_train_motion, y_train_motion)\n",
    "train_time_lr_no_scale = time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr_no_scale = lr_no_scale.predict(X_test_motion)\n",
    "\n",
    "# Calculate metrics\n",
    "acc_lr_no_scale = accuracy_score(y_test_motion, y_pred_lr_no_scale)\n",
    "f1_lr_no_scale = f1_score(y_test_motion, y_pred_lr_no_scale, average='weighted')\n",
    "\n",
    "print(f\"Training time: {train_time_lr_no_scale:.3f} seconds\")\n",
    "print(f\"Accuracy: {acc_lr_no_scale:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_lr_no_scale:.4f}\")\n",
    "\n",
    "# Measure inference time for single prediction\n",
    "single_sample = X_test_motion.iloc[0:1]\n",
    "inference_times = []\n",
    "for _ in range(100):\n",
    "    start = time()\n",
    "    _ = lr_no_scale.predict(single_sample)\n",
    "    inference_times.append((time() - start) * 1000)  # Convert to milliseconds\n",
    "\n",
    "avg_inference_lr_no_scale = np.mean(inference_times)\n",
    "print(f\"Average inference time (single sample): {avg_inference_lr_no_scale:.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logreg_with_scaler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression WITH StandardScaler (using Pipeline)\n",
    "print(\"=== Logistic Regression WITH StandardScaler ===\")\n",
    "\n",
    "start_time = time()\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "lr_pipeline.fit(X_train_motion, y_train_motion)\n",
    "train_time_lr_scaled = time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr_scaled = lr_pipeline.predict(X_test_motion)\n",
    "\n",
    "# Calculate metrics\n",
    "acc_lr_scaled = accuracy_score(y_test_motion, y_pred_lr_scaled)\n",
    "f1_lr_scaled = f1_score(y_test_motion, y_pred_lr_scaled, average='weighted')\n",
    "\n",
    "print(f\"Training time: {train_time_lr_scaled:.3f} seconds\")\n",
    "print(f\"Accuracy: {acc_lr_scaled:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_lr_scaled:.4f}\")\n",
    "\n",
    "# Measure inference time for single prediction\n",
    "inference_times = []\n",
    "for _ in range(100):\n",
    "    start = time()\n",
    "    _ = lr_pipeline.predict(single_sample)\n",
    "    inference_times.append((time() - start) * 1000)  # Convert to milliseconds\n",
    "\n",
    "avg_inference_lr_scaled = np.mean(inference_times)\n",
    "print(f\"Average inference time (single sample): {avg_inference_lr_scaled:.3f} ms\")\n",
    "\n",
    "print(\"\\n=== Comparison ===\")\n",
    "print(f\"Accuracy improvement: {(acc_lr_scaled - acc_lr_no_scale):.4f}\")\n",
    "print(f\"F1-score improvement: {(f1_lr_scaled - f1_lr_no_scale):.4f}\")\n",
    "print(\"\\nJustification: StandardScaler helps normalize features, which can improve convergence and performance.\")\n",
    "print(\"However, if the improvement is minimal, we can omit it to reduce computational overhead.\")\n",
    "if abs(acc_lr_scaled - acc_lr_no_scale) < 0.01:\n",
    "    print(\"In this case, the improvement is minimal, so StandardScaler may not be necessary.\")\n",
    "else:\n",
    "    print(\"In this case, StandardScaler provides noticeable improvement and should be retained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logreg_report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report for Logistic Regression (with scaler)\n",
    "print(\"\\nClassification Report (Logistic Regression with StandardScaler):\")\n",
    "print(classification_report(y_test_motion, y_pred_lr_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## 3. Random Forest Classifier\n",
    "\n",
    "Random Forest is an ensemble method that combines multiple decision trees to improve prediction accuracy.\n",
    "It is particularly useful for feature importance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random_forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"=== Random Forest Classifier ===\")\n",
    "\n",
    "start_time = time()\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train_motion, y_train_motion)\n",
    "train_time_rf = time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test_motion)\n",
    "\n",
    "# Calculate metrics\n",
    "acc_rf = accuracy_score(y_test_motion, y_pred_rf)\n",
    "f1_rf = f1_score(y_test_motion, y_pred_rf, average='weighted')\n",
    "\n",
    "print(f\"Training time: {train_time_rf:.3f} seconds\")\n",
    "print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_rf:.4f}\")\n",
    "\n",
    "# Measure inference time for single prediction\n",
    "inference_times = []\n",
    "for _ in range(100):\n",
    "    start = time()\n",
    "    _ = rf_model.predict(single_sample)\n",
    "    inference_times.append((time() - start) * 1000)  # Convert to milliseconds\n",
    "\n",
    "avg_inference_rf = np.mean(inference_times)\n",
    "print(f\"Average inference time (single sample): {avg_inference_rf:.3f} ms\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_motion, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Analysis (Random Forest)\n",
    "\n",
    "We analyze which facial landmark features contribute most to the model's predictions.\n",
    "Features are grouped by facial regions (e.g., mouth, eyes, eyebrows) to understand their relative importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 most important features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(range(20), feature_importance.head(20)['importance'].values)\n",
    "plt.yticks(range(20), feature_importance.head(20)['feature'].values)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "group_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group features by facial regions based on landmark indices\n",
    "# Typical facial landmark groupings (based on 68-point model):\n",
    "# Landmarks 1-17: Jaw line\n",
    "# Landmarks 18-22: Right eyebrow\n",
    "# Landmarks 23-27: Left eyebrow\n",
    "# Landmarks 28-36: Nose\n",
    "# Landmarks 37-42: Right eye\n",
    "# Landmarks 43-48: Left eye\n",
    "# Landmarks 49-68: Mouth\n",
    "\n",
    "def categorize_feature(feature_name):\n",
    "    \"\"\"Categorize feature by facial region based on landmark number\"\"\"\n",
    "    if feature_name[0] not in ['x', 'y']:\n",
    "        return 'other'\n",
    "    \n",
    "    try:\n",
    "        landmark_num = int(feature_name[1:])\n",
    "    except:\n",
    "        return 'other'\n",
    "    \n",
    "    if 1 <= landmark_num <= 17:\n",
    "        return 'jaw'\n",
    "    elif 18 <= landmark_num <= 27:\n",
    "        return 'eyebrows'\n",
    "    elif 28 <= landmark_num <= 36:\n",
    "        return 'nose'\n",
    "    elif 37 <= landmark_num <= 48:\n",
    "        return 'eyes'\n",
    "    elif 49 <= landmark_num <= 68:\n",
    "        return 'mouth'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Categorize and group importances\n",
    "feature_importance['region'] = feature_importance['feature'].apply(categorize_feature)\n",
    "region_importance = feature_importance.groupby('region')['importance'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nFeature importance by facial region:\")\n",
    "print(region_importance)\n",
    "\n",
    "# Plot region importances\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(region_importance.index, region_importance.values)\n",
    "plt.xlabel('Facial Region')\n",
    "plt.ylabel('Total Importance')\n",
    "plt.title('Feature Importance by Facial Region')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Mouth region features typically have the highest importance for emotion recognition.\")\n",
    "print(\"- Eyes and eyebrows are also significant contributors.\")\n",
    "print(\"- Jaw and nose features contribute less to emotion classification.\")\n",
    "print(\"\\nRecommendation for feature selection:\")\n",
    "print(\"- Retain: mouth, eyes, and eyebrow features (primary emotional indicators)\")\n",
    "print(\"- Consider removing: jaw features if computational efficiency is prioritized\")\n",
    "print(\"- Nose features can be retained as they provide structural context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## 5. Learning Curves for Random Forest\n",
    "\n",
    "### Effect of max_depth on model performance\n",
    "\n",
    "max_depth controls the maximum depth of each decision tree in the forest.\n",
    "Deeper trees can capture more complex patterns but may overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning_curve_depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve: varying max_depth\n",
    "max_depth_values = [2, 5, 10, 15, 20, 25, 30, None]\n",
    "train_accuracies_depth = []\n",
    "test_accuracies_depth = []\n",
    "\n",
    "print(\"Testing different max_depth values...\")\n",
    "for depth in max_depth_values:\n",
    "    rf_temp = RandomForestClassifier(n_estimators=50, max_depth=depth, random_state=42)\n",
    "    rf_temp.fit(X_train_motion, y_train_motion)\n",
    "    \n",
    "    train_acc = rf_temp.score(X_train_motion, y_train_motion)\n",
    "    test_acc = rf_temp.score(X_test_motion, y_test_motion)\n",
    "    \n",
    "    train_accuracies_depth.append(train_acc)\n",
    "    test_accuracies_depth.append(test_acc)\n",
    "    \n",
    "    depth_str = 'None' if depth is None else str(depth)\n",
    "    print(f\"max_depth={depth_str:>4}: Train Acc={train_acc:.4f}, Test Acc={test_acc:.4f}\")\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "x_labels = [str(d) if d is not None else 'None' for d in max_depth_values]\n",
    "x_pos = range(len(max_depth_values))\n",
    "plt.plot(x_pos, train_accuracies_depth, marker='o', label='Train Accuracy')\n",
    "plt.plot(x_pos, test_accuracies_depth, marker='s', label='Test Accuracy')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Random Forest: Effect of max_depth on Accuracy')\n",
    "plt.xticks(x_pos, x_labels, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Low max_depth values (2-5) lead to underfitting: both train and test accuracy are low.\")\n",
    "print(\"- As max_depth increases, training accuracy improves significantly.\")\n",
    "print(\"- Test accuracy initially improves but may plateau or decrease if trees become too deep (overfitting).\")\n",
    "print(\"- The optimal max_depth balances model complexity with generalization ability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "### Effect of n_estimators on model performance\n",
    "\n",
    "n_estimators is the number of decision trees in the forest.\n",
    "More trees generally improve performance but increase computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning_curve_estimators",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve: varying n_estimators\n",
    "n_estimators_values = [10, 25, 50, 75, 100, 150, 200]\n",
    "train_accuracies_est = []\n",
    "test_accuracies_est = []\n",
    "\n",
    "print(\"Testing different n_estimators values...\")\n",
    "for n_est in n_estimators_values:\n",
    "    rf_temp = RandomForestClassifier(n_estimators=n_est, max_depth=10, random_state=42)\n",
    "    rf_temp.fit(X_train_motion, y_train_motion)\n",
    "    \n",
    "    train_acc = rf_temp.score(X_train_motion, y_train_motion)\n",
    "    test_acc = rf_temp.score(X_test_motion, y_test_motion)\n",
    "    \n",
    "    train_accuracies_est.append(train_acc)\n",
    "    test_accuracies_est.append(test_acc)\n",
    "    \n",
    "    print(f\"n_estimators={n_est:>3}: Train Acc={train_acc:.4f}, Test Acc={test_acc:.4f}\")\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_estimators_values, train_accuracies_est, marker='o', label='Train Accuracy')\n",
    "plt.plot(n_estimators_values, test_accuracies_est, marker='s', label='Test Accuracy')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Random Forest: Effect of n_estimators on Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- With few trees (10-25), the model's performance is lower due to high variance.\")\n",
    "print(\"- As n_estimators increases, both train and test accuracy improve and stabilize.\")\n",
    "print(\"- Beyond a certain point (typically 100-150), additional trees provide diminishing returns.\")\n",
    "print(\"- The ensemble effect reduces variance by averaging predictions from multiple trees.\")\n",
    "print(\"- Higher n_estimators values increase training time linearly but improve model robustness.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "## 6. Decision Tree Classifier\n",
    "\n",
    "Decision Tree is a simpler model compared to Random Forest.\n",
    "It uses a single tree structure to make decisions, which is more interpretable but may be less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision_tree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree\n",
    "print(\"=== Decision Tree Classifier ===\")\n",
    "\n",
    "start_time = time()\n",
    "dt_model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "dt_model.fit(X_train_motion, y_train_motion)\n",
    "train_time_dt = time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_model.predict(X_test_motion)\n",
    "\n",
    "# Calculate metrics\n",
    "acc_dt = accuracy_score(y_test_motion, y_pred_dt)\n",
    "f1_dt = f1_score(y_test_motion, y_pred_dt, average='weighted')\n",
    "\n",
    "print(f\"Training time: {train_time_dt:.3f} seconds\")\n",
    "print(f\"Accuracy: {acc_dt:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_dt:.4f}\")\n",
    "\n",
    "# Measure inference time for single prediction\n",
    "inference_times = []\n",
    "for _ in range(100):\n",
    "    start = time()\n",
    "    _ = dt_model.predict(single_sample)\n",
    "    inference_times.append((time() - start) * 1000)  # Convert to milliseconds\n",
    "\n",
    "avg_inference_dt = np.mean(inference_times)\n",
    "print(f\"Average inference time (single sample): {avg_inference_dt:.3f} ms\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_motion, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8",
   "metadata": {},
   "source": [
    "## 7. Model Comparison (Motion Dataset)\n",
    "\n",
    "Compare all three models on the motion dataset in terms of accuracy, F1-score, training time, and inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison_motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_motion = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression (no scaler)', 'Logistic Regression (with scaler)', 'Random Forest', 'Decision Tree'],\n",
    "    'Accuracy': [acc_lr_no_scale, acc_lr_scaled, acc_rf, acc_dt],\n",
    "    'F1-Score': [f1_lr_no_scale, f1_lr_scaled, f1_rf, f1_dt],\n",
    "    'Training Time (s)': [train_time_lr_no_scale, train_time_lr_scaled, train_time_rf, train_time_dt],\n",
    "    'Inference Time (ms)': [avg_inference_lr_no_scale, avg_inference_lr_scaled, avg_inference_rf, avg_inference_dt]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison on Motion Dataset:\")\n",
    "print(comparison_motion.to_string(index=False))\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Random Forest typically achieves the highest accuracy and F1-score.\")\n",
    "print(\"- Decision Tree is faster to train but may have lower accuracy than Random Forest.\")\n",
    "print(\"- Logistic Regression has the fastest inference time.\")\n",
    "print(\"- Random Forest has the longest training time due to ensemble complexity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section9",
   "metadata": {},
   "source": [
    "## 8. Comparison Between Data Types: Motion vs Geometric\n",
    "\n",
    "Train all models on both motion and geometric datasets to determine which data representation is better suited for emotion classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "models_on_geometric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models on geometric dataset\n",
    "print(\"=== Training models on Geometric dataset ===\")\n",
    "\n",
    "# Logistic Regression (with scaler) on geometric\n",
    "lr_geo = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "lr_geo.fit(X_train_geometric, y_train_geometric)\n",
    "y_pred_lr_geo = lr_geo.predict(X_test_geometric)\n",
    "acc_lr_geo = accuracy_score(y_test_geometric, y_pred_lr_geo)\n",
    "f1_lr_geo = f1_score(y_test_geometric, y_pred_lr_geo, average='weighted')\n",
    "print(f\"Logistic Regression - Accuracy: {acc_lr_geo:.4f}, F1-score: {f1_lr_geo:.4f}\")\n",
    "\n",
    "# Per-class F1 scores for Logistic Regression (geometric)\n",
    "f1_lr_geo_per_class = f1_score(y_test_geometric, y_pred_lr_geo, average=None)\n",
    "\n",
    "# Random Forest on geometric\n",
    "rf_geo = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_geo.fit(X_train_geometric, y_train_geometric)\n",
    "y_pred_rf_geo = rf_geo.predict(X_test_geometric)\n",
    "acc_rf_geo = accuracy_score(y_test_geometric, y_pred_rf_geo)\n",
    "f1_rf_geo = f1_score(y_test_geometric, y_pred_rf_geo, average='weighted')\n",
    "print(f\"Random Forest - Accuracy: {acc_rf_geo:.4f}, F1-score: {f1_rf_geo:.4f}\")\n",
    "\n",
    "# Per-class F1 scores for Random Forest (geometric)\n",
    "f1_rf_geo_per_class = f1_score(y_test_geometric, y_pred_rf_geo, average=None)\n",
    "\n",
    "# Decision Tree on geometric\n",
    "dt_geo = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "dt_geo.fit(X_train_geometric, y_train_geometric)\n",
    "y_pred_dt_geo = dt_geo.predict(X_test_geometric)\n",
    "acc_dt_geo = accuracy_score(y_test_geometric, y_pred_dt_geo)\n",
    "f1_dt_geo = f1_score(y_test_geometric, y_pred_dt_geo, average='weighted')\n",
    "print(f\"Decision Tree - Accuracy: {acc_dt_geo:.4f}, F1-score: {f1_dt_geo:.4f}\")\n",
    "\n",
    "# Per-class F1 scores for Decision Tree (geometric)\n",
    "f1_dt_geo_per_class = f1_score(y_test_geometric, y_pred_dt_geo, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class F1 scores for motion dataset\n",
    "f1_lr_motion_per_class = f1_score(y_test_motion, y_pred_lr_scaled, average=None)\n",
    "f1_rf_motion_per_class = f1_score(y_test_motion, y_pred_rf, average=None)\n",
    "f1_dt_motion_per_class = f1_score(y_test_motion, y_pred_dt, average=None)\n",
    "\n",
    "# Create comprehensive comparison table\n",
    "comparison_datasets = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Logistic Regression', 'Random Forest', 'Random Forest', 'Decision Tree', 'Decision Tree'],\n",
    "    'Dataset': ['Motion', 'Geometric', 'Motion', 'Geometric', 'Motion', 'Geometric'],\n",
    "    'Accuracy': [acc_lr_scaled, acc_lr_geo, acc_rf, acc_rf_geo, acc_dt, acc_dt_geo],\n",
    "    'F1-Score (weighted)': [f1_lr_scaled, f1_lr_geo, f1_rf, f1_rf_geo, f1_dt, f1_dt_geo]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Comparison: Motion vs Geometric Datasets ===\")\n",
    "print(comparison_datasets.to_string(index=False))\n",
    "\n",
    "# Per-class F1 scores comparison\n",
    "emotion_classes = sorted(y_test_motion.unique())\n",
    "print(\"\\n=== Per-Class F1-Scores ===\")\n",
    "\n",
    "per_class_comparison = pd.DataFrame({\n",
    "    'Emotion': emotion_classes,\n",
    "    'LR_Motion': f1_lr_motion_per_class,\n",
    "    'LR_Geometric': f1_lr_geo_per_class,\n",
    "    'RF_Motion': f1_rf_motion_per_class,\n",
    "    'RF_Geometric': f1_rf_geo_per_class,\n",
    "    'DT_Motion': f1_dt_motion_per_class,\n",
    "    'DT_Geometric': f1_dt_geo_per_class\n",
    "})\n",
    "\n",
    "print(per_class_comparison.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "models = ['LR', 'RF', 'DT']\n",
    "motion_accs = [acc_lr_scaled, acc_rf, acc_dt]\n",
    "geometric_accs = [acc_lr_geo, acc_rf_geo, acc_dt_geo]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, motion_accs, width, label='Motion')\n",
    "axes[0].bar(x + width/2, geometric_accs, width, label='Geometric')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# F1-score comparison\n",
    "motion_f1s = [f1_lr_scaled, f1_rf, f1_dt]\n",
    "geometric_f1s = [f1_lr_geo, f1_rf_geo, f1_dt_geo]\n",
    "\n",
    "axes[1].bar(x - width/2, motion_f1s, width, label='Motion')\n",
    "axes[1].bar(x + width/2, geometric_f1s, width, label='Geometric')\n",
    "axes[1].set_ylabel('F1-Score (weighted)')\n",
    "axes[1].set_title('F1-Score Comparison')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(models)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Justification: Which Dataset is Better? ===\")\n",
    "avg_motion = np.mean([acc_lr_scaled, acc_rf, acc_dt])\n",
    "avg_geometric = np.mean([acc_lr_geo, acc_rf_geo, acc_dt_geo])\n",
    "\n",
    "print(f\"Average accuracy across all models - Motion: {avg_motion:.4f}, Geometric: {avg_geometric:.4f}\")\n",
    "\n",
    "if avg_motion > avg_geometric:\n",
    "    print(\"\\nConclusion: Motion dataset performs better on average.\")\n",
    "    print(\"Reason: Motion features capture temporal changes in facial expressions,\")\n",
    "    print(\"which are critical for emotion recognition. Dynamic changes (e.g., mouth movement,\")\n",
    "    print(\"eyebrow raising) provide stronger signals than static geometric positions.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Geometric dataset performs better on average.\")\n",
    "    print(\"Reason: Geometric features provide stable spatial relationships between facial landmarks,\")\n",
    "    print(\"which may be more robust to noise and individual variations compared to motion features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section10",
   "metadata": {},
   "source": [
    "## 9. Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Feature Importance**: Mouth and eye regions are the most important for emotion recognition.\n",
    "2. **Model Complexity**: Random Forest benefits from moderate depth and multiple trees.\n",
    "3. **Model Performance**: Random Forest typically achieves the best accuracy, followed by Decision Tree and Logistic Regression.\n",
    "4. **Data Type**: Motion or geometric features may perform differently depending on the dataset characteristics.\n",
    "5. **Standardization**: StandardScaler may or may not significantly improve Logistic Regression performance.\n",
    "6. **Timing**: Logistic Regression is fastest for inference, while Random Forest requires more training time.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "- For highest accuracy: Use Random Forest with optimized hyperparameters.\n",
    "- For real-time applications: Use Logistic Regression for faster inference.\n",
    "- For feature selection: Focus on mouth and eye regions; consider removing jaw features.\n",
    "- For data representation: Choose based on the specific characteristics of your dataset (motion vs geometric)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
